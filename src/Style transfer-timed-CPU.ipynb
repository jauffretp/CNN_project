{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#K.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 467\n",
      "Width : 700\n"
     ]
    }
   ],
   "source": [
    "content = image.load_img(\"chien.jpg\")\n",
    "content_array = image.img_to_array(content)\n",
    "\n",
    "\n",
    "height = content_array.shape[0]\n",
    "width = content_array.shape[1]\n",
    "\n",
    "\n",
    "style = image.load_img(\"style.jpg\", target_size=(height,width))\n",
    "style_array = image.img_to_array(style)\n",
    "\n",
    "content_array = np.expand_dims(content_array, axis=0)\n",
    "content_array = preprocess_input(content_array)\n",
    "\n",
    "style_array = np.expand_dims(style_array, axis=0)\n",
    "style_array = preprocess_input(style_array)\n",
    "\n",
    "\n",
    "assert content_array.shape == style_array.shape\n",
    "\n",
    "generated = K.placeholder(shape=(1,height, width, 3))\n",
    "content = K.variable(content_array)\n",
    "style = K.variable(style_array)\n",
    "\n",
    "print(\"Height :\",height)\n",
    "print(\"Width :\", width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = vgg19.VGG19(weights='imagenet', input_tensor=K.concatenate([content,style,generated], axis=0),include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gram(tensor):\n",
    "    arranged = K.permute_dimensions(tensor, (2,0,1))\n",
    "    arranged = K.batch_flatten(arranged)\n",
    "    return K.dot(arranged, K.transpose(arranged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def style_loss(gram_style,gram_generated,shape):\n",
    "    Ml = shape[1] * shape[2]\n",
    "    Nl = shape[3]\n",
    "    return K.sum(K.square(gram_generated - gram_style))/(4.*(Ml ** 2) * (Nl ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def content_loss(content,generated):\n",
    "    return K.sum(K.square(generated - content))/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layers_name = [layer.name for layer in model.layers]\n",
    "layers_style = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \"block5_conv1\"]\n",
    "layers_content = [\"block4_conv1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'block3_pool': (3, 58, 87, 256), 'block4_conv1': (3, 58, 87, 512), 'block2_conv1': (3, 233, 350, 128), 'block3_conv1': (3, 116, 175, 256), 'block2_conv2': (3, 233, 350, 128), 'block4_conv2': (3, 58, 87, 512), 'block2_pool': (3, 116, 175, 128), 'block1_pool': (3, 233, 350, 64), 'block1_conv2': (3, 467, 700, 64), 'block5_conv4': (3, 29, 43, 512), 'block5_pool': (3, 14, 21, 512), 'block4_conv3': (3, 58, 87, 512), 'block3_conv2': (3, 116, 175, 256), 'block5_conv3': (3, 29, 43, 512), 'input_1': (3, 467, 700, 3), 'block5_conv2': (3, 29, 43, 512), 'block1_conv1': (3, 467, 700, 64), 'block4_conv4': (3, 58, 87, 512), 'block3_conv4': (3, 116, 175, 256), 'block5_conv1': (3, 29, 43, 512), 'block4_pool': (3, 29, 43, 512), 'block3_conv3': (3, 116, 175, 256)}\n"
     ]
    }
   ],
   "source": [
    "dict_shape = {}\n",
    "for name in layers_name:\n",
    "    dict_shape[name] = model.get_layer(name).output_shape\n",
    "    \n",
    "print(dict_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_dict = dict((name,model.get_layer(name).output) for name in layers_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 467, 700, 64)\n",
      "(3, 233, 350, 128)\n",
      "(3, 116, 175, 256)\n",
      "(3, 58, 87, 512)\n",
      "(3, 29, 43, 512)\n"
     ]
    }
   ],
   "source": [
    "loss_variable = K.variable(0)\n",
    "content_coeff = 0.0001 #content\n",
    "style_coeff = 1 #style\n",
    "\n",
    "loss_style_variable = K.variable(0)\n",
    "for name in layers_style:\n",
    "    layer = model_dict[name]\n",
    "    layer_generated = layer[2,:,:,:]\n",
    "    layer_style = layer[1,:,:,:]\n",
    "    \n",
    "    gram_style = gram(layer_style)\n",
    "    gram_generated = gram(layer_generated)\n",
    "    \n",
    "    shape = dict_shape[name]\n",
    "    print(shape)\n",
    "    loss_style_variable +=  (style_loss(gram_style, gram_generated,shape)/len(layers_style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss_content_variable = K.variable(0.)\n",
    "for name in layers_content:\n",
    "    layer = model_dict[name]\n",
    "    layer_generated = layer[2,:,:,:]\n",
    "    layer_content = layer[0,:,:,:]\n",
    "    loss_content_variable += (content_loss(layer_content, layer_generated)) / len(layers_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_loss = content_coeff * loss_content_variable + style_coeff * loss_style_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gradients = K.gradients(total_loss, generated)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evaluate_loss_grads = K.function([generated], [total_loss, gradients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_img(img_data, height, width):\n",
    "    img = img_data.reshape((height, width, 3))\n",
    "\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    \n",
    "    \n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Doing Nesterov acceleration\n",
    "\n",
    "iterate = K.function([generated], [gradients, total_loss])\n",
    "num_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.0, 1.618033988749895]\n",
      "[1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "losses = []\n",
    "\n",
    "smooth_number = 550.\n",
    "lambdas = [0]\n",
    "for i in range(num_epoch + 1):\n",
    "    last_lambda = lambdas[i]\n",
    "    new_lambda = (1. + math.sqrt(1. + 4.*(last_lambda**2.) ))/2.\n",
    "    lambdas.append(new_lambda)\n",
    "print(lambdas)\n",
    "\n",
    "gammas = [(1. - lambdas[i])/lambdas[i+1] for i in range(len(lambdas) - 1)]\n",
    "\n",
    "print(gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ys = [0.]\n",
    "img_data = np.random.uniform(110,150,((1, height, width,3)))\n",
    "img_data = preprocess_input(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0\n",
      "1.02058e+10\n",
      "CPU times: user 2min 26s, sys: 4.27 s, total: 2min 30s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for it in range(num_epoch):\n",
    "    print(\"Epoch : \" , it)\n",
    "    \n",
    "    grads_values, loss_values = iterate([img_data])\n",
    "    print(loss_values)\n",
    "    \n",
    "    losses.append(loss_values)\n",
    "    \n",
    "    \n",
    "    ys_1 = img_data - (1. / smooth_number) * grads_values\n",
    "    ys.append(ys_1)\n",
    "    current_ys = ys[it]\n",
    "    \n",
    "    \n",
    "    img_data = (1 - gammas[it + 1]) * ys_1 + gammas[it] * ys[it]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate_loss_grads_from_flatten(flatten_input):   \n",
    "    correct_input = flatten_input.reshape((1, height, width, 3))\n",
    "    loss, grads= evaluate_loss_grads([correct_input])\n",
    "    return loss, grads.flatten().astype('float64')\n",
    "\n",
    "\n",
    "def getLoss(state):\n",
    "    def getLoss_input(flatten_input):\n",
    "        loss_values, grads_values = evaluate_loss_grads_from_flatten(flatten_input)\n",
    "        state[\"loss\"] = loss_values\n",
    "        state[\"gradients\"] = grads_values.flatten()\n",
    "        #print(\"New state : \",state)\n",
    "        return loss_values\n",
    "    return getLoss_input\n",
    "\n",
    "def getGrads(state):\n",
    "    def getGrads_input(flatten_input):\n",
    "\n",
    "        grads = state[\"gradients\"]\n",
    "        return grads.copy()\n",
    "    \n",
    "    return getGrads_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "\n",
    "state = {}\n",
    "\n",
    "img_data = np.random.uniform(110,150,((1, height, width,3)))\n",
    "img_data = preprocess_input(img_data)\n",
    "\n",
    "\n",
    "loss_lbfgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 32s, sys: 24 s, total: 14min 56s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "for it in range(num_epoch):\n",
    "    min_input, min_val, info = fmin_l_bfgs_b(getLoss(state), img_data.flatten(),fprime=getGrads(state), maxiter=3, maxfun=5)\n",
    "    \n",
    "    loss_lbfgs.append(min_val)\n",
    "    img_data = min_input.reshape((1, height, width, 3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
